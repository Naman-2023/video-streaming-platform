# Video Streaming Platform

A modern event-driven microservices video streaming platform with Kafka integration, automatic transcoding, and HLS streaming.

## Features

- ğŸ¬ **Video Upload**: Upload multiple video formats (MP4, AVI, MOV, MKV, WebM, FLV)
- ğŸ”„ **Auto Transcoding**: Automatic conversion to multiple qualities (360p, 720p, 1080p)
- ğŸ“º **HLS Streaming**: HTTP Live Streaming with adaptive bitrate
- âš¡ **Real-time Status**: Track upload and transcoding progress via Redis
- ğŸš€ **Event-Driven**: Kafka-powered job queue for reliable processing
- ğŸ¯ **Scalable Architecture**: Horizontally scalable worker processes
- ğŸ”’ **Security**: Helmet.js security headers and CORS protection
- ğŸ“Š **Health Monitoring**: Built-in health checks for all services
- ğŸ’ª **Fault Tolerant**: Durable job processing with automatic retries
- ğŸ”§ **TypeScript**: Full TypeScript implementation with strict typing

## Quick Start

### Prerequisites

- Node.js 18+
- Docker & Docker Compose
- FFmpeg installed

### 1. Start Infrastructure (Kafka + Redis)

```bash
docker-compose up -d
```

This starts:

- **Kafka**: Event streaming platform (Port 9092)
- **Zookeeper**: Kafka coordination service (Port 2181)
- **Redis**: Status cache and rate limiting (Port 6379)

### 2. Install Dependencies

```bash
npm install
cd services/upload-service && npm install
cd ../streaming-service && npm install
cd ../transcoding-service && npm install
cd ../..
```

### 3. Start Platform

```bash
node start-platform.js
```

The platform will start on:

- **API Gateway: http://localhost:3000** (Main Entry Point)
- Upload Service: http://localhost:3001
- Streaming Service: http://localhost:3004
- Transcoding Service: http://localhost:3005

## Usage

### Upload a Video

**Via API Gateway (Recommended):**

```bash
curl -X POST -F "video=@your-video.mp4;type=video/mp4" -F "title=My Video" \
     http://localhost:3000/api/upload/file
```

**Direct to Upload Service:**

```bash
curl -X POST -F "video=@your-video.mp4;type=video/mp4" -F "title=My Video" \
     http://localhost:3001/api/v1/upload/file
```

Response:

```json
{
  "success": true,
  "data": {
    "jobId": "job_1758010126855_6lecfzv3a",
    "status": "QUEUED",
    "message": "File uploaded successfully and queued for processing"
  },
  "timestamp": "2025-09-16T08:08:46.869Z"
}
```

> **Note**: Transcoding starts automatically! No manual API call needed.

### Check Status

**Via API Gateway (Recommended):**

```bash
curl http://localhost:3000/api/upload/status/job_1758010126855_6lecfzv3a
```

**Direct to Upload Service:**

```bash
curl http://localhost:3001/api/v1/upload/status/job_1758010126855_6lecfzv3a
```

Response:

```json
{
  "success": true,
  "data": {
    "jobId": "job_1758010126855_6lecfzv3a",
    "status": "COMPLETED",
    "progress": 100,
    "currentStep": "Transcoding completed successfully",
    "estimatedTimeRemaining": 0
  },
  "timestamp": "2025-09-16T08:08:59.641Z"
}
```

### Stream Video

Once transcoding is complete, stream using:

**Via API Gateway (Recommended):**

```
http://localhost:3000/api/stream/job_1758010126855_6lecfzv3a/master.m3u8
http://localhost:3000/api/stream/job_1758010126855_6lecfzv3a/360p/playlist.m3u8
http://localhost:3000/api/stream/job_1758010126855_6lecfzv3a/720p/playlist.m3u8
http://localhost:3000/api/stream/job_1758010126855_6lecfzv3a/1080p/playlist.m3u8
```

**Direct to Streaming Service:**

```
http://localhost:3004/api/v1/stream/job_1758010126855_6lecfzv3a/master.m3u8
http://localhost:3004/api/v1/stream/job_1758010126855_6lecfzv3a/360p/playlist.m3u8
http://localhost:3004/api/v1/stream/job_1758010126855_6lecfzv3a/720p/playlist.m3u8
http://localhost:3004/api/v1/stream/job_1758010126855_6lecfzv3a/1080p/playlist.m3u8
```

### Play in VLC

1. Open VLC Media Player
2. Go to Media â†’ Open Network Stream
3. Paste the master playlist URL
4. Click Play

## Architecture - Event-Driven Microservices

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   API Gateway   â”‚
                    â”‚   Port: 3000    â”‚ â† Single Entry Point
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
        â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Upload Service â”‚    â”‚ Transcoding      â”‚    â”‚ Streaming       â”‚
â”‚  Port: 3001     â”‚    â”‚ Workers          â”‚    â”‚ Service         â”‚
â”‚                 â”‚    â”‚ Port: 3005       â”‚    â”‚ Port: 3004      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Kafka       â”‚    â”‚     Redis       â”‚    â”‚   File System   â”‚
â”‚   Port: 9092    â”‚    â”‚   Port: 6379    â”‚    â”‚   (transcoded)  â”‚
â”‚ Event Streaming â”‚    â”‚ Status & Cache  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Zookeeper     â”‚
â”‚   Port: 2181    â”‚
â”‚  Coordination   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Event Flow: Upload â†’ Kafka Topic â†’ Worker Consumes â†’ Processing â†’ Ready Event
```

### ğŸ”„ Event-Driven Workflow

1. **Upload**: User uploads video â†’ Upload Service saves file
2. **Queue**: Upload Service publishes job to `video.transcoding.jobs` topic
3. **Process**: Transcoding Worker consumes job from Kafka
4. **Status**: Worker updates progress in Redis during processing
5. **Complete**: Worker publishes completion to `video.streaming.ready` topic
6. **Stream**: Video ready for HLS streaming

### Services

- **API Gateway**: Single entry point with routing, rate limiting, and health checks
- **Upload Service**: Handles file uploads and publishes jobs to Kafka
- **Transcoding Workers**: Consumer group that processes videos from Kafka queue
- **Streaming Service**: Serves HLS playlists and video segments

### Infrastructure

- **Kafka**: Event streaming platform for reliable job processing
  - `video.transcoding.jobs` - Main job queue (durable, fault-tolerant)
  - `video.streaming.ready` - Completion notifications
  - `transcoding-workers` - Consumer group for load balancing
- **Redis**: Real-time status updates and API rate limiting
- **Zookeeper**: Kafka coordination and metadata management

### ğŸš€ Scalability Benefits

- **Horizontal Scaling**: Run multiple transcoding workers
- **Fault Tolerance**: Jobs survive worker crashes
- **Load Balancing**: Kafka distributes jobs across workers
- **Durability**: Messages persisted until processed

## File Structure

```
video-streaming-platform/
â”œâ”€â”€ api-gateway/                 # API Gateway (Port 3000)
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ index.ts            # Main gateway with routing
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ shared/                  # Shared utilities and types
â”‚   â”‚   â”œâ”€â”€ types.ts            # Common TypeScript interfaces
â”‚   â”‚   â””â”€â”€ utils.ts            # Shared utility functions
â”‚   â”œâ”€â”€ upload-service/          # File upload and Kafka publisher
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ routes/          # Upload API routes
â”‚   â”‚       â”œâ”€â”€ kafka.ts         # Kafka producer configuration
â”‚   â”‚       â”œâ”€â”€ index.ts         # Main entry point
â”‚   â”‚       â””â”€â”€ routes.ts        # Route exports
â”‚   â”œâ”€â”€ streaming-service/       # HLS streaming
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â””â”€â”€ index.ts         # Main entry point with streaming routes
â”‚   â””â”€â”€ transcoding-service/     # Video processing workers
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ kafka.ts         # Kafka consumer configuration
â”‚           â”œâ”€â”€ index.ts         # Main API entry point
â”‚           â””â”€â”€ worker.ts        # Kafka consumer worker process
â”œâ”€â”€ transcoded/                  # Processed video files
â”œâ”€â”€ docker-compose.yml          # Kafka, Zookeeper, Redis infrastructure
â”œâ”€â”€ start-platform.js           # Platform launcher
â”œâ”€â”€ test-platform.sh           # Comprehensive test suite
â””â”€â”€ README.md                   # This file
```

## Technology Stack

- **Backend**: Node.js, TypeScript, Express.js
- **Event Streaming**: Apache Kafka + Zookeeper
- **Caching**: Redis
- **Video Processing**: FFmpeg
- **Streaming**: HLS (HTTP Live Streaming)
- **Infrastructure**: Docker, Docker Compose
- **Architecture**: Event-Driven Microservices

## Development

### Test Platform

Run comprehensive tests:

```bash
./test-platform.sh
```

### Stop Platform

```bash
# Stop services
Press Ctrl+C in the terminal running start-platform.js

# Stop infrastructure
docker-compose down
```

### Clean Environment

```bash
# Clean transcoded files
rm -rf transcoded/*
rm -rf services/upload-service/uploads/*

# Reset Redis
docker exec redis-server redis-cli flushall

# Reset Kafka topics (optional)
docker-compose down -v
docker-compose up -d
```

### Build Services

```bash
# Build all services
npm run build

# Build individual service
cd services/upload-service && npm run build
```

### Scale Workers

```bash
# Run multiple transcoding workers for load testing
npm run worker &
npm run worker &
npm run worker &
```

### Monitor Kafka

```bash
# List topics
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# Monitor job queue
docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic video.transcoding.jobs --from-beginning

# Monitor completion events
docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic video.streaming.ready --from-beginning
```

## Troubleshooting

### Infrastructure Issues

**Kafka Connection Failed:**

```bash
# Check if Kafka is running
docker ps | grep kafka

# Restart infrastructure
docker-compose down && docker-compose up -d

# Check Kafka logs
docker logs kafka
```

**Redis Connection Failed:**

```bash
# Check if Redis is running
docker ps | grep redis

# Test Redis connection
docker exec redis-server redis-cli ping
```

### Service Issues

**FFmpeg Not Found:**

```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html
```

**Port Already in Use:**

```bash
# Kill existing processes
pkill -f "npm run dev"
pkill -f "tsx"

# Check what's using ports
lsof -i :3000,3001,3004,3005,9092,6379
```

**Worker Not Processing Jobs:**

```bash
# Check if worker is connected to Kafka
docker logs kafka | grep transcoding-workers

# Manually start worker
cd services/transcoding-service && npm run worker

# Check Kafka consumer groups
docker exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 --list
```

### Performance Issues

**Slow Transcoding:**

```bash
# Run multiple workers
npm run worker &
npm run worker &

# Check system resources
htop
```

**High Memory Usage:**

```bash
# Restart services
docker-compose restart

# Check Docker stats
docker stats
```

## License

MIT License
